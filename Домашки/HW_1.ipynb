{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №1: линейная регрессия и векторное дифференцирование (10 баллов).\n",
    "\n",
    "* Некоторые задания будут по вариантам (всего 4 варианта). Чтобы выяснить свой вариант, посчитайте количество букв в своей фамилии, возьмите остаток от деления на 4 и прибавьте 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есаян = 5 букв\n",
    "\n",
    "5 % 4 + 1 = 2 вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Многомерная линейная регрессия из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим многомерную регрессию из sklearn для стандартного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples = 10000)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас 10000 объектов и 100 признаков. Для начала решим задачу аналитически \"из коробки\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3947402571022364e-25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.35131177e-14,  5.68434189e-14, -7.10542736e-15,  6.56591813e+00,\n",
       "       -5.32907052e-15,  7.81597009e-14,  1.73194792e-14, -3.55271368e-15,\n",
       "       -6.39488462e-14,  2.37587727e-14,  1.64155379e+01,  1.77761650e+01,\n",
       "       -1.95399252e-14,  3.55271368e-15, -3.19744231e-14, -1.10134124e-13,\n",
       "        1.73194792e-14, -1.77635684e-15,  8.43769499e-15,  5.95079541e-14,\n",
       "        1.59872116e-14, -9.68114477e-14, -2.08721929e-14, -2.66453526e-14,\n",
       "        2.05391260e-14, -4.52970994e-14, -7.10542736e-15, -4.17443857e-14,\n",
       "       -5.06261699e-14,  1.77635684e-15, -3.10862447e-15,  1.42108547e-14,\n",
       "       -2.30926389e-14, -2.30926389e-14,  2.57571742e-14,  7.99360578e-15,\n",
       "        9.99200722e-15, -7.54951657e-15,  9.76996262e-15, -1.52100554e-14,\n",
       "        3.59712260e-14,  2.30926389e-14,  3.37507799e-14, -4.57411886e-14,\n",
       "       -4.44089210e-14,  6.21724894e-14,  1.19904087e-14, -1.42108547e-14,\n",
       "        1.77635684e-14,  9.73606083e+01, -1.59872116e-14,  9.36343986e+01,\n",
       "        2.08721929e-14, -2.13162821e-14,  3.46389584e-14, -6.92779167e-14,\n",
       "       -5.32907052e-15,  3.05311332e-14, -4.44089210e-15, -4.97379915e-14,\n",
       "       -2.22044605e-14, -6.83897383e-14,  2.26485497e-14, -5.32907052e-14,\n",
       "        1.79856130e-14,  2.22044605e-14,  1.11022302e-14,  2.16135406e+01,\n",
       "        0.00000000e+00,  3.73034936e-14, -2.02060590e-14,  0.00000000e+00,\n",
       "       -4.88498131e-14,  1.68753900e-14,  2.66453526e-15,  1.33226763e-14,\n",
       "        9.35028445e+01, -3.01980663e-14, -5.55111512e-14,  1.13738205e+01,\n",
       "        1.68753900e-14, -3.46389584e-14, -1.77635684e-15,  3.80806497e-14,\n",
       "       -3.55271368e-14, -6.66133815e-15,  2.75907754e+01, -2.75335310e-14,\n",
       "        2.46469511e-14,  2.15383267e-14,  3.92786095e+01,  1.64313008e-14,\n",
       "        2.66453526e-14,  2.93098879e-14, -6.75015599e-14,  1.95399252e-14,\n",
       "       -1.06581410e-14,  7.06101844e-14, -8.54871729e-15, -7.99360578e-14])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем обучить линейную регрессию методом градиентного спуска \"из коробки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.082105740111725e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3.68402357e-07, -1.13535010e-07,  1.86935665e-07,  6.56591700e+00,\n",
       "       -4.38334170e-07,  3.76401407e-07,  1.25000937e-07,  3.39338755e-07,\n",
       "        4.87525702e-07,  1.19336974e-07,  1.64155365e+01,  1.77761632e+01,\n",
       "       -9.50190521e-08, -2.64870092e-07,  3.58796212e-07,  1.17983819e-07,\n",
       "       -1.53832446e-08,  5.07897595e-08, -2.04123860e-07,  4.10059282e-07,\n",
       "        3.51692791e-07, -4.24776892e-07, -3.85013047e-07, -6.81069704e-07,\n",
       "        6.32062628e-07,  2.83269459e-07, -2.56108139e-07,  5.71618280e-07,\n",
       "       -3.02694060e-07, -2.18085642e-07,  6.38258940e-07,  3.82163421e-07,\n",
       "        3.20326696e-07, -2.35140919e-07, -3.61159682e-07,  3.07989613e-07,\n",
       "       -4.86825399e-07,  3.16703831e-07, -3.12232998e-08, -1.66093067e-07,\n",
       "       -3.39979814e-07,  7.39551108e-08,  3.75967227e-07,  2.87431921e-07,\n",
       "        3.07528916e-07, -8.15395308e-07, -3.39825983e-07, -3.06102669e-07,\n",
       "       -4.03523761e-07,  9.73605986e+01, -6.60015206e-07,  9.36343897e+01,\n",
       "        1.99211576e-07,  1.16535917e-07, -3.02857137e-07,  3.24878428e-07,\n",
       "        1.71418592e-07, -1.95143292e-07,  2.28684180e-07, -2.57301680e-07,\n",
       "       -1.15185146e-07, -2.06121178e-07,  1.51484053e-07,  9.29696978e-08,\n",
       "        3.67774951e-07,  2.64349971e-07, -6.31510511e-07,  2.16135381e+01,\n",
       "        4.22352710e-07, -5.50398607e-07, -3.37162711e-07, -1.36468316e-07,\n",
       "       -7.06412802e-08,  7.19604913e-08,  3.01149502e-07, -1.15675605e-06,\n",
       "        9.35028351e+01,  6.37844525e-08,  2.78309322e-07,  1.13738193e+01,\n",
       "       -1.53797253e-07,  1.26233588e-08, -6.36814743e-08, -3.03243404e-07,\n",
       "       -2.06986207e-07,  1.85922231e-08,  2.75907726e+01,  1.74027600e-07,\n",
       "       -5.28455202e-10, -1.72941986e-07,  3.92786055e+01,  8.74381519e-08,\n",
       "       -2.13610943e-07, -1.35088229e-07,  9.76312084e-07, -2.09191851e-07,\n",
       "        1.05084105e-07, -2.10157486e-07, -3.68004268e-07, -1.95530397e-07])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "reg = SGDRegressor(alpha=0.0000001).fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Задание 1 (0.5 балла).*** Объясните, чем вызвано различие двух полученных значений метрики?\n",
    "\n",
    "***Ответ:*** в sklearn имплементации линейной регрессии получили MSE в 10^15 раз меньше, чем в SGDRegressor. В SGDRegressor используется L1-регуляризация, не позволяющая слишком идеально обучить модель на искуственных данных (так как регуляризация используется как-раз таки для того, чтобы не переобучить модель), а в sklearn LinearRegression() регуляризации нет.\n",
    "\n",
    "***Задание 2 (0.5 балла).*** Подберите гиперпараметры в методе градиентного спуска так, чтобы значение MSE было близко к значению MSE, полученному при обучении LinearRegression.\n",
    "\n",
    "***Ответ:*** при alpha=0 или очень-очень близком к нулю получим одинаковые MSE (см. ниже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3463399809659515e-25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "reg = SGDRegressor(alpha=0.000000).fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили MSE = 5.3463399809659515e-25 vs MSE = 1.3947402571022364e-25 -- более близкие значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ваша многомерная линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Задание 3 (4 балла)***. Напишите собственную многомерную линейную регрессию, оптимизирующую MSE методом *градиентного спуска*. Для этого используйте шаблонный класс. \n",
    "\n",
    "Критерий останова: либо норма разности весов на текущей и предыдущей итерациях меньше определенного значения (первый и третий варианты), либо модуль разности функционалов качества (MSE) на текущей и предыдущей итерациях меньше определенного значения (второй и четвертый варианты). Также предлагается завершать обучение в любом случае, если было произведено слишком много итераций.\n",
    "\n",
    "***Задание 4 (2 балла)***. Добавьте l1 (первый и второй варианты) или l2 (третий и четвертый варианты) регуляризацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self, alpha=0.0001, l_ratio=0.001, tol=0.001, max_iter=1000):\n",
    "        '''\n",
    "        Для начала необходимо инициализировать параметры\n",
    "        alpha - это learning rate или шаг обучения\n",
    "        l_ratio - параметр регуляризации\n",
    "        tol - значение для критерия останова\n",
    "        max_iter - максимальное количество итераций обучения\n",
    "        '''\n",
    "        self.alpha_ = alpha\n",
    "        self.l_ratio_ = l_ratio\n",
    "        self.tol_ = tol\n",
    "        self.max_iter_ = max_iter\n",
    "             \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Метод для обучения линейной регрессии\n",
    "        X - матрица признаков\n",
    "        y - вектор правильных ответов\n",
    "        '''\n",
    "        self.costs_ = []\n",
    "        self.coef_ = np.zeros((X.shape[1], ))\n",
    "        m = X.shape[0]\n",
    "        i = 0\n",
    "        while i <= self.max_iter_:\n",
    "            y_pred = np.dot(X, self.coef_)\n",
    "            residual = y_pred - y\n",
    "            gradient_vector = 2 * np.dot(X.T, residual) + self.l_ratio_ * np.sign(self.coef_)\n",
    "            self.coef_ -= (self.alpha_ / m) * gradient_vector\n",
    "            cost = np.sum(residual ** 2) / m\n",
    "            self.costs_.append(cost)\n",
    "            \n",
    "            if i > 1 and abs(self.costs_[i] - self.costs_[i - 1]) < self.tol_:\n",
    "                break\n",
    "            else:\n",
    "                i += 1\n",
    "        return self\n",
    "        \n",
    "   \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Метод для предсказаний линейной регрессии\n",
    "        X - матрица признаков\n",
    "        '''\n",
    "        \n",
    "        return np.dot(X, self.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are amazing! Great work!\n"
     ]
    }
   ],
   "source": [
    "my_reg = LinearRegression(alpha = 0.1, tol = 0.0001, l_ratio = 0.01)\n",
    "my_reg.fit(X, y)\n",
    "\n",
    "assert mean_squared_error(y, my_reg.predict(X)) < 1e-3\n",
    "print('You are amazing! Great work!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001230608151993754"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, my_reg.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8a81576460>]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAawElEQVR4nO3dfXBVdZ7n8ff33jwYkgAhuSDkgWCLrUgLYoahxtl+kHGk3R5xptpdrO2RrrWWLgd77Z3endX+Z2Znytp2p1pn3FqttdUS+0lZu3then1YB/vJWgsNCioPNuE5giQBgQAmIcl3/7i/KzfhklzydJKcz6vq1j33e87v5neOyIdzzu/8Yu6OiIhIIuoOiIjI+KBAEBERQIEgIiKBAkFERAAFgoiIBAVRd2CoqqqqvL6+PupuiIhMKFu2bGlz91SudRM2EOrr62lsbIy6GyIiE4qZHbjYOl0yEhERQIEgIiKBAkFERAAFgoiIBAoEEREBFAgiIhIoEEREBIhhILy1/zgPvbwLTfstItJX7AJh26ETPP6rPZz85FzUXRERGVdiFwip8mIA2k53RtwTEZHxJXaBUFWWDoTW9q6IeyIiMr7ELhAyZwitOkMQEekjdoGQOUNoa1cgiIhki10gTC8pJJkw3UMQEekndoGQSBiVpUUKBBGRfmIXCJC+j9CqS0YiIn3EMhCqyoppO61RRiIi2WIcCDpDEBHJFs9AKE/fQ9D0FSIi58UyEFJlxZzrcU1fISKSJZ6BoOkrREQuEMtA0PQVIiIXinUg6AxBROS8WAbCp/MZ6VkEEZFPxTIQNH2FiMiFYhkImr5CRORCgwaCmdWa2S/NbKeZbTez+0L9b8zsQzPbGl63ZrV5wMyazOwDM7slq36Dmb0X1j1qZhbqxWb2fKhvNrP6UdjXPvS0sohIX/mcIXQD33b3a4BlwFozWxDWPeLui8PrRYCwbhVwLbACeMzMkmH7x4E1wPzwWhHqdwMfu/uVwCPAQ8PftYFpPiMRkb4GDQR3P+Lub4fldmAnUD1Ak5XAc+7e6e77gCZgqZnNBqa6+xuefkT4WeD2rDbrwvILwPLM2cNo0fQVIiJ9XdI9hHAp53pgcyjda2bvmtnTZlYRatXAoaxmzaFWHZb71/u0cfdu4CRQmePnrzGzRjNrbG1tvZSuX6CqvIhjp7s0fYWISJB3IJhZGfBT4Fvufor05Z/PAIuBI8D3MpvmaO4D1Adq07fg/oS7N7h7QyqVyrfrOaXKiunq6eXUJ93D+h4Rkckir0Aws0LSYfAjd/8ZgLsfdfced+8Fvg8sDZs3A7VZzWuAw6Fek6Pep42ZFQDTgOND2aF8nf/dyh2j+WNERCaMfEYZGfAUsNPdH86qz87a7E+B98PyRmBVGDk0j/TN4zfd/QjQbmbLwnfeBWzIarM6LH8VeM1H+VqOpq8QEemrII9tbgT+HHjPzLaG2neAO81sMelLO/uBbwC4+3YzWw/sID1Caa2794R29wDPACXAS+EF6cD5gZk1kT4zWDWcncqHpq8QEelr0EBw99fJfY3/xQHaPAg8mKPeCCzMUe8A7hisLyOpqqwIUCCIiGTE8kllgIopRSQTpmcRRESC2AaCpq8QEekrtoEAmr5CRCRbvAOhXE8ri4hkxDoQUmWaz0hEJCPWgaDpK0REzot1IGj6ChGR8+IdCJ9OX6HLRiIisQ6E89NXKBBERBQI6GllERGIfSBo+goRkYxYB0Jm+goFgohIzAMhM32F7iGIiMQ8EEDTV4iIZCgQNH2FiAigQCBVVkybLhmJiCgQqsqLaNP0FSIiCgRNXyEikhb7QPj0aWXdRxCRmIt9IGTmM9KNZRGJu9gHguYzEhFJUyBo+goREUCBoOkrRESC2AdCZvqKtnY9rSwi8Rb7QID0fQSNMhKRuFMgoOkrRERAgQCkbyxr+goRibtBA8HMas3sl2a208y2m9l9oT7DzF41s93hvSKrzQNm1mRmH5jZLVn1G8zsvbDuUTOzUC82s+dDfbOZ1Y/Cvl5UqrxY01eISOzlc4bQDXzb3a8BlgFrzWwBcD+wyd3nA5vCZ8K6VcC1wArgMTNLhu96HFgDzA+vFaF+N/Cxu18JPAI8NAL7ljdNXyEikkcguPsRd387LLcDO4FqYCWwLmy2Drg9LK8EnnP3TnffBzQBS81sNjDV3d/w9D/Fn+3XJvNdLwDLM2cPY0HTV4iIXOI9hHAp53pgMzDL3Y9AOjSAmWGzauBQVrPmUKsOy/3rfdq4ezdwEqjM8fPXmFmjmTW2trZeStcHlAkE3VgWkTjLOxDMrAz4KfAtdz810KY5aj5AfaA2fQvuT7h7g7s3pFKpwbqcN81nJCKSZyCYWSHpMPiRu/8slI+Gy0CE95ZQbwZqs5rXAIdDvSZHvU8bMysApgHHL3VnhiozfYXmMxKROMtnlJEBTwE73f3hrFUbgdVheTWwIau+Kowcmkf65vGb4bJSu5ktC995V782me/6KvCaj+GQH01fISICBXlscyPw58B7ZrY11L4DfBdYb2Z3AweBOwDcfbuZrQd2kB6htNbde0K7e4BngBLgpfCCdOD8wMyaSJ8ZrBrebl2aRMKYoekrRCTmBg0Ed3+d3Nf4AZZfpM2DwIM56o3Awhz1DkKgRCVVpqeVRSTe9KRyUFWu+YxEJN4UCIGmrxCRuFMgBOlLRpq+QkTiS4EQpMrD9BUdmr5CROJJgRDodyuLSNwpEAJNXyEicadACKrK008rKxBEJK4UCEEqc4agS0YiElMKhKBiShEFCeOoAkFEYkqBECQSRk1FCQePnY26KyIikVAgZJlbWcr+Y2ei7oaISCQUCFnmVZWyv+2MHk4TkVhSIGSZWzmFM109tJ3WrKciEj8KhCz1VaUAumwkIrGkQMgyrzIEQpsCQUTiR4GQpbqihGTCdIYgIrGkQMhSmExQW1HCfg09FZEYUiD0M7eyVJeMRCSWFAj9zKsq5cCxsxp6KiKxo0DoZ27lFE53dmvoqYjEjgKhHw09FZG4UiD0U6+hpyISUwqEfmo09FREYkqB0I+GnopIXCkQctDQUxGJIwVCDhp6KiJxNGggmNnTZtZiZu9n1f7GzD40s63hdWvWugfMrMnMPjCzW7LqN5jZe2Hdo2ZmoV5sZs+H+mYzqx/hfbxkGnoqInGUzxnCM8CKHPVH3H1xeL0IYGYLgFXAtaHNY2aWDNs/DqwB5odX5jvvBj529yuBR4CHhrgvIyYz9PSAbiyLSIwMGgju/hvgeJ7ftxJ4zt073X0f0AQsNbPZwFR3f8PT12GeBW7ParMuLL8ALM+cPUQlM/R0n+4jiEiMDOcewr1m9m64pFQRatXAoaxtmkOtOiz3r/dp4+7dwEmgMtcPNLM1ZtZoZo2tra3D6PrAMkNPD2ikkYjEyFAD4XHgM8Bi4AjwvVDP9S97H6A+UJsLi+5PuHuDuzekUqlL6vClKEwmqKkoYZ8uGYlIjAwpENz9qLv3uHsv8H1gaVjVDNRmbVoDHA71mhz1Pm3MrACYRv6XqEZNvYaeikjMDCkQwj2BjD8FMiOQNgKrwsiheaRvHr/p7keAdjNbFu4P3AVsyGqzOix/FXjNx8F4z/rKKRp6KiKxUjDYBmb2E+CLQJWZNQN/DXzRzBaTvrSzH/gGgLtvN7P1wA6gG1jr7j3hq+4hPWKpBHgpvACeAn5gZk2kzwxWjcB+DVt9VemnQ09T5cVRd0dEZNQNGgjufmeO8lMDbP8g8GCOeiOwMEe9A7hjsH6MteyhpwoEEYkDPal8ERp6KiJxo0C4CA09FZG4USBchIaeikjcKBAGUF9ZqukrRCQ2FAgDqK+cwv42DT0VkXhQIAwgM/T02BnNeioik58CYQD6/coiEicKhAFknkXQ0FMRiQMFwgA09FRE4kSBMAANPRWROFEgDEJDT0UkLhQIg9DQUxGJCwXCIDT0VETiQoEwCA09FZG4UCAMIjP0dL9GGonIJKdAGERm6KnOEERkslMgDCIz9HS/RhqJyCSnQMhDfWWpAkFEJj0FQh409FRE4kCBkIerZ0/ldGe3biyLyKSmQMjDkroKAN4+8HHEPRERGT0KhDzMn1lGeXEBWw4qEERk8lIg5CGRMBbXTdcZgohMagqEPC2pq+B3R9s53dkddVdEREaFAiFPS+ZW0Ouw7dCJqLsiIjIqFAh5Wlw7HYAtumwkIpPUoIFgZk+bWYuZvZ9Vm2Fmr5rZ7vBekbXuATNrMrMPzOyWrPoNZvZeWPeomVmoF5vZ86G+2czqR3gfR8S0kkKumlXG27qxLCKTVD5nCM8AK/rV7gc2uft8YFP4jJktAFYB14Y2j5lZMrR5HFgDzA+vzHfeDXzs7lcCjwAPDXVnRtuSugreOXiC3l49oCYik8+ggeDuvwGO9yuvBNaF5XXA7Vn159y90933AU3AUjObDUx19zc8/bjvs/3aZL7rBWB55uxhvFlSV8HJT86xVxPdicgkNNR7CLPc/QhAeJ8Z6tXAoaztmkOtOiz3r/dp4+7dwEmgMtcPNbM1ZtZoZo2tra1D7PrQLZmrB9REZPIa6ZvKuf5l7wPUB2pzYdH9CXdvcPeGVCo1xC4O3RVVpUwrKdR9BBGZlIYaCEfDZSDCe0uoNwO1WdvVAIdDvSZHvU8bMysApnHhJapxIZEwrq+brkAQkUlpqIGwEVgdllcDG7Lqq8LIoXmkbx6/GS4rtZvZsnB/4K5+bTLf9VXgNR/H04ouqatgd8tpTn5yLuquiIiMqHyGnf4EeAP4rJk1m9ndwHeBm81sN3Bz+Iy7bwfWAzuAl4G17t4Tvuoe4EnSN5r3AC+F+lNApZk1AX9JGLE0Xt0wtwJ32KoH1ERkkikYbAN3v/Miq5ZfZPsHgQdz1BuBhTnqHcAdg/VjvFhUO52EpW8sf+Gqsb+PISIyWvSk8iUqKy7gqlnluo8gIpOOAmEIlsytYKseUBORSUaBMAQ31FXQ3tnN7pbTUXdFRGTEKBCG4NMH1HTZSEQmEQXCENRXTmFGaZGeWBaRSUWBMARmxpK66fqVmiIyqSgQhuj6ugr2tp7hxNmuqLsiIjIiFAhDtKQufR/hnYMnou2IiMgIUSAM0aLaaSQTphvLIjJpKBCGaEpRAdfMLtev1BSRSUOBMAxL6irYdugEPXpATUQmAQXCMCypq+BMVw8ffNQedVdERIZNgTAMmRvLjQfG5a9vEBG5JAqEYaidUcK8qlJefv+jqLsiIjJsCoRhMDNuWzSHN/Ye4+ipjqi7IyIyLAqEYbpt8Rzc4RfvHom6KyIiw6JAGKbPpMpYWD2VjVs/jLorIiLDokAYAbctmsO25pPsbzsTdVdERIZMgTAC/mTRHMxg47bDUXdFRGTIFAgjYPa0En6vfgYbtn6Iux5SE5GJSYEwQlYunsOe1jPsOHIq6q6IiAyJAmGE3LpwNgUJY+NWXTYSkYlJgTBCKkqL+PxVKf5p22F6NbeRiExACoQRtHLxHA6f7KBRM6CKyASkQBhBf3TNLC4rTLBxm55JEJGJR4EwgkqLC7h5weX8n3ePcK6nN+ruiIhckmEFgpntN7P3zGyrmTWG2gwze9XMdof3iqztHzCzJjP7wMxuyarfEL6nycweNTMbTr+idNuiOXx89hyvN7VF3RURkUsyEmcIX3L3xe7eED7fD2xy9/nApvAZM1sArAKuBVYAj5lZMrR5HFgDzA+vFSPQr0h84aoU00oKNdpIRCac0bhktBJYF5bXAbdn1Z9z90533wc0AUvNbDYw1d3f8PRTXc9mtZlwigoSfHnh5byy/SM+6eqJujsiInkbbiA48H/NbIuZrQm1We5+BCC8zwz1auBQVtvmUKsOy/3rE9Zti+dwtquHTbuORt0VEZG8DTcQbnT3JcCXgbVm9vkBts11X8AHqF/4BWZrzKzRzBpbW1svvbdj5PfnVTJrajEbdNlIRCaQYQWCux8O7y3Az4GlwNFwGYjw3hI2bwZqs5rXAIdDvSZHPdfPe8LdG9y9IZVKDafroyqZMFYuruaXu1rYpxlQRWSCGHIgmFmpmZVnloE/Bt4HNgKrw2argQ1heSOwysyKzWwe6ZvHb4bLSu1mtiyMLrorq82E9e/+xRUUFST4+1d2Rd0VEZG8FAyj7Szg52GEaAHwY3d/2czeAtab2d3AQeAOAHffbmbrgR1AN7DW3TN3Xe8BngFKgJfCa0JLlRez5vNX8A//vJu3D37MkrqKwRuJiETIJup0zQ0NDd7Y2Bh1NwZ0prObL/z9r7iiqpTnv7GMCfx4hYhMEma2JesxgT70pPIoKi0u4D/cPJ839x/nn3e2DN5ARCRCCoRR9q8barkiVcp3X9pJt6azEJFxTIEwygqSCf7ziqvZ03qG/7WlefAGIiIRUSCMgT9eMIuGuRU8/OrvONvVHXV3RERyUiCMATPjgVuvprW9kyd/uy/q7oiI5KRAGCM3zJ3Bimsv53/+eg9tpzuj7o6IyAUUCGPoP634LB3dvTy6aXfUXRERuYACYQx9JlXGnUtr+fHmg+xpPR11d0RE+lAgjLH7ll/FlKIkf/HDt2nvOBd1d0REPqVAGGOp8mIe/9oN7Gk9zb0/fkfPJojIuKFAiMCNV1bxd7cv5Ne/a+XvfrEj6u6IiADDm9xOhuHOpXXsbT3N93+7j3lVpXz9xnlRd0lEYk6BEKH7v3wN+9rO8re/2MHcylK+dPXMwRuJiIwSXTKKUDJh/OOqxVx9+VS++ZN32PXRqai7JCIxpkCIWGlxAU99vYHS4iR3P9NIS3tH1F0SkZhSIIwDs6eV8ORdv8fxM118/em3aP74bNRdEpEYUiCME5+rmcZjX1vCoeNn+cp/f53Xdh2NuksiEjMKhHHkS5+dyT998w+ZPa2Ef/tMI//t5V16TkFExowCYZypryrl53/xB9y5tJbHfrWHf/PkZlpO6b6CiIw+BcI4dFlhkv/6Z9fx8L9axLvNJ7n10df5f3vaou6WiExyCoRx7M+W1LDh3huZPqWQrz25mb96YRsHjp2JulsiMkkpEMa5q2aVs2Htjaz+g3o2bD3MTd/7NX+5fqtmSxWREWfuHnUfhqShocEbGxuj7saYajnVwRO/2csPNx+gq7uXr1w3h2/edCXzZ5VH3TURmSDMbIu7N+Rcp0CYeNpOd/L93+7lB28c4JNzPdz02Znc+rnZLL9mJtOnFEXdPREZxxQIk9TxM108/fo+XtjSzEenOihIGMuuqOSWhZdzy4JZzJx6WdRdFJFxRoEwyfX2Ou9+eJJXtn/EK+9/xN629I3n6+ums7R+BtfVTOe6mmnUVJRgZhH3VkSipECIEXenqeU0L7//EZt2tbDj8Cm6wsNtlaVFfK5mGtfVTGfB7HLqZpRSVzmFsmJNeisSFxMiEMxsBfCPQBJ40t2/O9D2CoT8dHb38MFH7WxrPsm7h07wbvNJdre005v1n72ytIi6yinUzZhCbcUUZk4tpqqsmMrSIqrKi6kqLWZqSYHOLkQmgXEfCGaWBH4H3Aw0A28Bd7r7RX+dmAJh6M52dbO39QwHj5/lwLGzHDx+loPH058Pn+igp/fCPxOFSWP6lCLKiwsov6yA8ssKKQvLZZcVMKUoSUlhksvCq6QwSUlRkuKCBIXJ9KuoIEFRMkFhgaVriQTJpFGQMJKJ9HtBMkHSjEQCEmZhWUEkMlIGCoTxcq1gKdDk7nsBzOw5YCWg3y85CqYUFbCwehoLq6ddsK6n1zl+potjZzppa0+/t7Z30na6i5OfdHGqo5v2jm5Od5zj6KmO9HJnN2e7usmRIyMmmTASBmbp94QZCTMsLJuBcX49ZNfAwuf0Gvqc7XxaD9tl1zLbn9/24uF00TUD5NnFVk3Es7GJ1+OJ698vn8+fLJoz4t87XgKhGjiU9bkZ+P3+G5nZGmANQF1d3dj0LGaSCSNVXkyqvBguz7+du3Oux+no7qGjq4dPzqVfXd296VdPL+d6nK7uXs71pF/dPU5Pr9Pd63T3pj939/bS0wu97vT2Oj3hvddJL7vjnv55vX5+O4d0nfT6dDhltk3X+XSb9HvYIrOQWSL7rDk74wY6mb7YqoHOwC+6JvqT9kvmE7HTE9i0ksJR+d7xEgi5/nFxwZ8wd38CeALSl4xGu1OSPzOjqMAoKkgw9bLR+cMqIqNrvExd0QzUZn2uAQ5H1BcRkVgaL4HwFjDfzOaZWRGwCtgYcZ9ERGJlXFwycvduM7sXeIX0sNOn3X17xN0SEYmVcREIAO7+IvBi1P0QEYmr8XLJSEREIqZAEBERQIEgIiKBAkFERIBxMpfRUJhZK3BgiM2rgLj/1nodAx0D0DGI4/7PdfdUrhUTNhCGw8waLza5U1zoGOgYgI5B3Pe/P10yEhERQIEgIiJBXAPhiag7MA7oGOgYgI5B3Pe/j1jeQxARkQvF9QxBRET6USCIiAgQw0AwsxVm9oGZNZnZ/VH3ZyyY2dNm1mJm72fVZpjZq2a2O7xXRNnH0WRmtWb2SzPbaWbbzey+UI/TMbjMzN40s23hGPyXUI/NMYD07283s3fM7Bfhc6z2fzCxCgQzSwL/A/gysAC408wWRNurMfEMsKJf7X5gk7vPBzaFz5NVN/Btd78GWAasDf/d43QMOoGb3H0RsBhYYWbLiNcxALgP2Jn1OW77P6BYBQKwFGhy973u3gU8B6yMuE+jzt1/AxzvV14JrAvL64Dbx7JPY8ndj7j722G5nfRfCNXE6xi4u58OHwvDy4nRMTCzGuBfAk9mlWOz//mIWyBUA4eyPjeHWhzNcvcjkP4LE5gZcX/GhJnVA9cDm4nZMQiXS7YCLcCr7h63Y/APwF8BvVm1OO3/oOIWCJajpnG3MWFmZcBPgW+5+6mo+zPW3L3H3ReT/p3lS81sYcRdGjNm9hWgxd23RN2X8SxugdAM1GZ9rgEOR9SXqB01s9kA4b0l4v6MKjMrJB0GP3L3n4VyrI5BhrufAH5F+r5SXI7BjcBtZraf9KXim8zsh8Rn//MSt0B4C5hvZvPMrAhYBWyMuE9R2QisDsurgQ0R9mVUmZkBTwE73f3hrFVxOgYpM5selkuAPwJ2EZNj4O4PuHuNu9eT/v/+NXf/GjHZ/3zF7kllM7uV9LXEJPC0uz8YbY9Gn5n9BPgi6al+jwJ/DfxvYD1QBxwE7nD3/jeeJwUz+0Pgt8B7nL9+/B3S9xHicgyuI33TNEn6H4Lr3f1vzaySmByDDDP7IvAf3f0rcdz/gcQuEEREJLe4XTISEZGLUCCIiAigQBARkUCBICIigAJBREQCBYKIiAAKBBERCf4/x7FnJwHQC00AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(my_reg.costs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Задание 5 (1 балл)***. Обучите линейную регрессию из коробки\n",
    "\n",
    "* с l1-регуляризацией (from sklearn.linear_model import Lasso, **первый и второй вариант**) или с l2-регуляризацией (from sklearn.linear_model import Ridge, **третий и четвертый вариант**)\n",
    "* со значением параметра регуляризации **0.1 - для первого и третьего варианта, 0.01 - для второго и четвертого варианта**. \n",
    "\n",
    "Обучите вашу линейную регрессию с тем же значением параметра регуляризации и сравните результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010130280293980426"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha = 0.01)\n",
    "lasso_reg.fit(X, y)\n",
    "\n",
    "lasso_reg.predict(X)\n",
    "mean_squared_error(y, lasso_reg.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличив параметр регуляризации, увеличивается MSE (позволяем модели не переобучаться на обучающихся данных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Задание 6 (1 балл).***\n",
    "Пусть $P, Q \\in \\mathbb{R}^{n\\times n}$. Найдите $\\nabla_Q tr(PQ)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $P = (p_{ij}), Q = (q_{ij})$. Втупую посчитаем $tr(PQ) = \\sum_i^n \\sum_j^n p_{ij}q_{ji}$.\n",
    "\n",
    "Частная производная $\\frac{\\delta tr(PQ)}{\\delta q_{ij}} = p_{ji}$.\n",
    "\n",
    "В результате получим, что $\\nabla_Q tr(PQ) = P^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Задание 7 (1 балл).***\n",
    "Пусть $x, y \\in \\mathbb{R}^{n}, M \\in \\mathbb{R}^{n\\times n}$. Найдите $\\nabla_M x^T M y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем $\\nabla_M x^T M y$\n",
    "\n",
    "Считаем втупую: $\\nabla_M x^T M y = \\sum_i^n \\sum_j^n y_i m_{ij} x_j$\n",
    "\n",
    "\n",
    "Частная производная $\\frac{\\delta \\nabla_M x^T M y}{\\delta m_{ij}} = y_i x_j$.\n",
    "\n",
    "Значит, $\\nabla_M x^T M y = xy^T$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решения заданий 6 и 7 можно написать на листочке и отправить в anytask вместе с заполненным ноутбуком."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
